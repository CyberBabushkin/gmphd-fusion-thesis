The Gaussian Mixture Probability Hypothesis Density (GM-PHD) filter was proposed in 2006 by Vo and Ma in \cite{voGaussianMixtureProbability2006} as a closed-form solution for the Gaussian-linear case of the general PHD filter and quickly became popular. As mentioned in the previous section, the PHD filter does not propagate the full posterior distribution, which eliminates the need to compute hypothesis likelihoods between measurements and existing targets. Therefore, the resulting filter is not computationally expensive as hypotheses-oriented filters like the MHT filter or filters that are built on top of the FISST theory and utilize random finite sets and the convolution formula to compute the full posterior distribution at each time step.

In the GM-PHD filter, the posterior intensity function is described by a Gaussian mixture. The same applies to the initial prior distribution and birth components. The clutter is modeled using a Poisson Point Process. Both the prediction and update steps utilize the equations that were inferred in the previous section, and the target dynamics and the single-target measurement likelihood are modeled using the standard Kalman filter equations. In this section, we will give a formal definition of the GM-PHD filter along with the exact algorithm. All relations described in this section follow those provided in \cite{voGaussianMixtureProbability2006} with the addition of labels (or tags) for Gaussian components from \cite{clarkGMPHDFilterMultiple2006} to enable basic track management. It should be noted that the notation in this work is slightly modified to stay consistent with the notation given in previous sections. Moreover, as noted before, we assume that existing targets cannot spawn additional targets, so the independence of targets' dynamics is preserved.
