The Probability Hypothesis Density (PHD) filter is a popular approach to multi-target tracking, especially when the number of targets is unknown and varies over time. The general formulation of the filter was first introduced by Mahler \cite{mahlerMultitargetBayesFiltering2003} as a direct application of the probability hypothesis density function. The filter is based on finite set statistics (FISST), covered briefly in Section \ref{sec:fisst}, and works by propagating the first-order multi-target moment, or the PHD function, in time instead of the full posterior distribution. This greatly reduces the computational burden of the filter compared to traditional hypotheses-based methods such as the MHT filter.

In 2003, Vo proposed the sequential Monte Carlo implementation of the PHD filter \cite{voSequentialMonteCarlo2003}, known as the SMC-PHD filter. However, this implementation had several drawbacks, such as a high computational cost due to the large number of particles required for distribution approximation and the reliance on clustering techniques for state estimation. Later, in 2006, Vo and Ma introduced a closed-form solution for the Gaussian-linear case \cite{voGaussianMixtureProbability2006}, called the GM-PHD filter. For non-linear models, the authors suggested implementations that utilize non-linear Kalman filters, such as the Unscented Kalman Filter and the Extended Kalman Filter. The versions of the PHD filter with these linearization techniques were called UK-PHD and EK-PHD, respectively. The GM-PHD filter was a significant improvement over the SMC-PHD filter in terms of computational efficiency while still providing accurate estimates of the number of targets and their states. The GM-PHD filter is the main topic of this work.

% PHD assumptions: \cite[588--590]{mahlerStatisticalMultisourcemultitargetInformation2007}