% Bayesian inference
    % - [x] Overview of Bayesian inference and its advantages over frequentist methods
    % - [x] Sequential application
% Estimators
    % - [x] MLE and MAP
    % - [x] What is better and why

In statistics, there are two ways to understand the uncertainty. The first one,
called \textit{frequentist}, assumes that the source of uncertainty lays in the
nature of events. If we modeled a random process following this approach, we 
would calculate parameters of the model using their maximum likelihood 
estimation, which in fact is the probability density function if the parameter 
evaluated at the observed data (we will talk more about estimators in Section 
\ref{sec:estimators}). In addition to the estimated parameter 
value, we could also calculate confidence intervals, which would give us a 
range where a possible true value of the parameter can lay considering some 
probability of possible error.

The \textit{Bayesian} approach has a different philosophy. It main
assumption is that the uncertainty origin is in the modeling itself and that
this are we who have limited knowledge about the ground true model. This
difference leads to a completely distinct path of estimating values of a model.
At the beginning, we give parameters a \textit{prior distribution}, our
initial belief where true values of parameters may lay. Next, after every new
data piece we update the distribution using the Bayes' rule. Using the
\textit{likelihood function}, which represents our updated beliefs about the
parameter after observing the data, and the prior, we compute the
\textit{posterior distribution}, the updated belief about the value of the
parameter. And, in an every subsequent step, the posterior becomes a new prior.

One of the main differences, however, in these two approaches is the output of 
such estimation. While in the frequentist statistics we get values of 
parameters, the Bayesian approach will give us a full posterior distribution of 
parameter values. From such a distribution, we can extract information for our 
needs, such as an estimation of a value or some uncertainty measure.

In object tracking, the Bayesian approach to estimation has several advantages. 
Firstly, we can estimate the posterior as time passes, one measurement at a 
time. This is good because rarely do we have all measurements in advance, and 
often we want our systems to work in an online manner. Secondly, full 
posteriors allow us to work with the uncertainty of estimation and implement 
techniques to reduce the number of new hypotheses using merging 
techniques.\footnote{
    As we will see later, the GM-PHD filter uses the Mahalanobis distance 
    between Gaussians to decide what hypotheses should be merged into one. The 
    computation of Mahalanobis distance includes the covariance matrix.
}

Last but not least, the Bayesian approach allows us to incorporate prior 
knowledge about the motion models of objects and their birth positions. All of 
the above helps to improve tracking performance and reduce the impact of noisy 
measurements.

\subsection{Bayes' rule in terms of pdfs}

In Bayesian object tracking, probability distributions are used instead of pure 
probabilities. Therefore, Bayes' rule must be defined using distributions. 
Fortunately, this is straightforward after we define the conditional probability in terms of pdfs.

\begin{definition}[Conditional probability for pdfs]\label{def:cond-prob-pdf}
    Let $x$ and $y$ be random variables with pdfs $p(x)$ and $p(y)$, respectively, and the joint distribution $p(x,y)$. Then the conditional probability of $x$ given $y$ is defined as:
    \begin{equation*}
        p(x|y) = \frac{p(x,y)}{p(y)}.
    \end{equation*}
\end{definition}

\begin{definition}[Bayes' rule for pdfs]
    Let $z$ and $x$ be random variables with densities $p(z | x)$ and $p(x)$, 
    respectively, and let $p(z, x)$ be their joint distribution. The Bayes' rule
    for 
    $p(x | z)$ is defined as follows:

    $$
    p(x | z)
        = \frac{p(z | x) p(x)}{p(z)}
        = \frac{p(z | x) p(x)}{\int p(z | x) p(x) dx}.
    $$
\end{definition}

The distribution $p(x | z)$ is the posterior distribution, $p(z | x)$ is the 
likelihood, $p(x)$ is the prior, and $p(z)$ is called \textit{evidence}.

Evidence here is only the normalization constant for the distribution so
that the integral of the posterior equals to one. It is therefore convenient
to omit this denominator in the text and write the posterior only in terms of
prior and likelihood. Since it is not already the equality, we use the
proportionality symbol:

$$
p(x | z) \propto p(z | x) p(x).
$$

We can use the rule defined above to compute the posterior of some parameter
based on all the data. However, in many real-world applications, measurements
do not arrive all at once, but rather sequentially over time. In the context of 
object tracking, sensors generate measurements in a discrete manner, once per
some predefined time interval, and the goal of the tracking algorithm to 
estimate targets' state at each time step. Fortunately, the construction of the
Bayes' rule allows us to define the sequential data update in a very 
straightforward manner.

\begin{theorem}[Sequential Bayes' rule]
    Let $z_k$ be an observed random variable at discrete time steps
    $k = 1, 2, \ldots$ and let $z_{1:k-1}$ represent the realizations of $z_k$ 
    obtained from the time step $k = 1$ up to $(k-1)$, that is $z_{1:k-1} = 
    \{z_1, z_2,\ldots, z_{k-1}\}$. Let $p(x_k | z_{1:k-1})$ denote the posterior 
    distribution obtained at time $k-1$ using all the measurements up to $k-1$ 
    and $p(z_k | x_k)$ be the likelihood of the new measurement $z_k$. The 
    posterior distribution $p(x_k | z_{1:k})$ at time step $k$ is:
    \todo{The alignment of the formula is awful. Check later}
    $$
    p(x_k | z_{1:k}) 
        = \frac
            { p(z_k | x_k) p(x_k | z_{1:k-1}) }
            { p(z_k | x_k) p(x_k | z_{1:k-1}) dx_k }
        \propto p(z_k | x_k) p(x_k | z_{1:k-1}).
    $$
\end{theorem}

It should be mentioned that $x_k$ and $z_k$ must not always be scalars. As we
will later see, they can be vectors, denoted as $\mathbf{x}_k$ and 
$\mathbf{z}_k$, or even sets, denoted $X_k$ and $Z_k$. The Bayes' rule will
have the same form in any case.

The application of the Bayes' rule has one big disadvantage. In practice, 
calculating the posterior can be challenging or even intractable. The evidence 
term in the denominator contains the integral of the product of the likelihood 
and the prior over the whole measurement space. This product may (and often 
will) produce functions whose integration cannot be expressed in a closed-form 
solution.

However, we can obtain a tractable solution by choosing a prior distribution 
from a set of \textit{conjugate distributions} with respect to the likelihood. 
In this case, the posterior will be in the same form as the prior and we obtain 
an explicit closed-form solution. A conjugate prior for a given likelihood 
function is a prior distribution that, when used in combination with the 
likelihood, leads to a posterior distribution that is in the same family as the 
prior.

For example, if the likelihood is expressed using the Bernoulli distribution 
and the prior is the Beta distribution, the posterior will also be a Beta 
distribution. The same applies for the Gaussian distribution, where if both the 
prior and the likelihood are Gaussian, the posterior is also Gaussian. This is 
particularly useful in practice, as many distributions have well-known 
conjugate priors. The latter case is used, for instance, in the GM-PHD filter.

\subsection{Estimators}\label{sec:estimators}

As mentioned before, the output of the Bayesian inference is always a
distribution. However, we are often interested in obtaining an estimated value
of the parameter we are estimating. \textit{Estimators} do exactly that.
Strictly speaking, estimators take a set of observations and produce an 
estimate of the value of an unknown parameter of a distribution. We denote an
estimate of an unknown parameter $x$ as $\hat{x}$. There are several known 
estimators but we are interested in two of them: ML and MAP.

The \textit{Maximum Likelihood (ML)} estimator finds the value of the parameter 
such that it maximizes the likelihood function. Formally:

$$
\hat{x}_{\mathrm{ML}} = \arg \max_x p(z|x).
$$

The ML estimator is a point estimator that finds the parameter value that 
makes the observed data most probable. For instance, the frequentist approach
uses this estimator to find the parameter value. The MLE does not take the 
prior distribution into account and is more sensitive to outliers. 
\todo{Citation needed}

The \textit{Maximum A Posteriori (MAP)} estimator, on the other hand, finds the 
value of the parameter that maximizes the posterior distribution. In formal 
notation:

$$
\hat{x}_{\mathrm{MAP}} = \arg \max_x p(x|z) = \arg \max_x p(z|x)p(x).
$$

The MAP estimator finds the most probable value of the parameter given the 
observed data. Comparing to the MLE, MAP uses prior information and more robust
when the data is noisy or incomplete. That is the reason why MAP is often used
in Bayesian inference.\footnote{
    In this work, we use Gaussian posterior distributions and MAP estimates are 
    equal to posterior mean estimates, or MMSE-estimates. However, for general 
    distributions, it will rarely be the case.
}
